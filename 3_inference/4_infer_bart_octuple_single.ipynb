{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfc3088-89be-4083-989d-3cbc3a471847",
   "metadata": {},
   "source": [
    "### Infer single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54616499-4aa6-4106-b05f-5b2f8e508329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['PYTHONPATH'] = '/home/qihao/CS6207'\n",
    "sys.path.append('/home/qihao/CS6207')\n",
    "import pickle\n",
    "import random\n",
    "import subprocess\n",
    "import torch.cuda\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.earlystopping.protocols import EarlyStopping\n",
    "from utils.test_dataloder import *\n",
    "import datetime\n",
    "from utils.get_time import get_time\n",
    "import gc, copy\n",
    "from tqdm import tqdm\n",
    "from utils.warmup import *\n",
    "import torch.nn.functional as F\n",
    "from models.bartmodel_octuple import Bart\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import prosodic as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4e696daa-1c57-4b35-8aad-3c65bde8fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7b52e9a3-3226-4ca6-982b-c357a3e23789",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_name = 'checkpoint_20240406:190014_lr_5e-05'\n",
    "# ckpt_name = 'checkpoint_20240406:144930_lr_5e-05'\n",
    "ckpt_dir = f'/data1/qihao/cs6207/octuple/checkpoints/{ckpt_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2303fc-2852-44c4-8955-85b5f7c37874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da90aa88-dabb-44e9-8df1-6215d474e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_keys = ['strength', 'length', 'phrase']\n",
    "tgt_keys = ['bar', 'pos', 'token', 'dur', 'phrase']\n",
    "\n",
    "binary_dir = '/data1/qihao/cs6207/octuple/binary'\n",
    "words_dir = '/data1/qihao/cs6207/octuple/binary/words' ## pretrain\n",
    "# words_dir = '/data1/qihao/cs6207/octuple/binary_909/words' ## 909\n",
    "hparams = {\n",
    "    'batch_size': 1,\n",
    "    'word_data_dir': words_dir,\n",
    "    'sentence_maxlen': 512,\n",
    "    'hidden_size': 768,\n",
    "    'n_layers': 6,\n",
    "    'n_head': 8,\n",
    "    'pretrain': '',\n",
    "    'lr': 5.0e-5,\n",
    "    'optimizer_adam_beta1': 0.9,\n",
    "    'optimizer_adam_beta2': 0.98,\n",
    "    'weight_decay': 0.001,\n",
    "    'patience': 5,\n",
    "    'warmup': 2500,\n",
    "    'lr': 5.0e-5,\n",
    "    'checkpoint_dir': '/home/qihao/CS6207/octuple/checkpoints',\n",
    "    'drop_prob': 0.2,\n",
    "    'total_epoch': 1000,\n",
    "    'infer_batch_size': 1,\n",
    "    'temperature': 1.6,\n",
    "    'topk': 5,\n",
    "    'prompt_step': 1,\n",
    "    'infer_max_step': 1024,\n",
    "    'output_dir': \"/home/qihao/CS6207/octuple/output\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9f197dd9-a209-46c7-96e8-664a52ed6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=1234):  # seed setting\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # cuDNN在使用deterministic模式时（下面两行），可能会造成性能下降（取决于model）\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5601fb7c-9c8f-4808-8180-c3ba34201b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path, device):\n",
    "    model = Bart(event2word_dict=event2word_dict, \n",
    "                 word2event_dict=word2event_dict, \n",
    "                 model_pth='',\n",
    "                 hidden_size=hparams['hidden_size'], \n",
    "                 num_layers=hparams['n_layers'], \n",
    "                 num_heads=hparams['n_head'], \n",
    "                 dropout=hparams['drop_prob'],).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device), strict=True)\n",
    "    model.eval()\n",
    "    print(f\"| Successfully loaded bart ckpt from {checkpoint_path}.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ab05e2b0-a7ec-4d65-96be-87178a053308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xe_loss(outputs, targets):\n",
    "    outputs = outputs.transpose(1, 2)\n",
    "    return F.cross_entropy(outputs, targets, ignore_index=0, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a52c66ee-3f64-4cbe-a126-674ae7e7a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_data(data_sample, event2word_dict, word2event_dict):   \n",
    "    data = {}\n",
    "    for key, value in data_sample.items():\n",
    "        end_name, dict_key = key.split('_')\n",
    "        if dict_key.lower() == 'token':\n",
    "            dict_key = 'Pitch'\n",
    "        else:\n",
    "            dict_key = dict_key[0].upper() + dict_key[1:].lower()\n",
    "        input_tokens = []\n",
    "        for v in value:\n",
    "            input_tokens.append(event2word_dict[dict_key][v])\n",
    "        data[key] = torch.LongTensor([copy.deepcopy(input_tokens)])\n",
    "\n",
    "    ## tgt_input:\n",
    "\n",
    "    '''\n",
    "    data = {\n",
    "        'src_strength': torch.LongTensor([[5, 3, 5, 3, 5, 3]]),\n",
    "        'src_length': torch.LongTensor([[3, 3, 4, 4, 4, 3]]),\n",
    "        'src_phrase': torch.LongTensor([[4, 4, 4, 4, 4, 3]]),\n",
    "        'tgt_bar': torch.LongTensor([[1, 3]]),\n",
    "        'tgt_pos': torch.LongTensor([[1, 75]]),\n",
    "        'tgt_token': torch.LongTensor([[1, 63]]),\n",
    "        'tgt_dur': torch.LongTensor([[1, 22]]),\n",
    "        'tgt_phrase': torch.LongTensor([[1, 4]]),\n",
    "    }\n",
    "    '''\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "205889ac-625d-4c1d-852f-8a3be0b28fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosodic as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9511adee-3e90-42a4-bdc2-7966185dffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosodic as p\n",
    "def convert_lyrics_to_input (lyrics):\n",
    "    text = p.Text(lyrics)\n",
    "\n",
    "    rep = 5\n",
    "    data_sample = {\n",
    "        'src_strength': ['<strong>', '<weak>', '<strong>', '<weak>', '<weak>', '<weak>', '<strong>']*rep*4,\n",
    "        'src_length': ['<short>', '<short>', '<short>', '<short>', '<short>', '<short>', '<long>']*rep*4,\n",
    "        'src_phrase': [],\n",
    "        'tgt_bar': [\"<s>\", \"Bar_0\"],\n",
    "        'tgt_pos': [\"<pad>\", \"Pos_0\"],\n",
    "        'tgt_token': [\"<pad>\", \"Pitch_60\"],\n",
    "        'tgt_dur': [\"<pad>\", \"Dur_120\"],\n",
    "        'tgt_phrase': [\"<pad>\", \"<false>\"],\n",
    "    }\n",
    "    \n",
    "    for line_id, line in enumerate(text.lines()):\n",
    "        words = line.words()\n",
    "        line_syllables = line.syllables()\n",
    "        line_syllable_num = len(line_syllables)\n",
    "\n",
    "        bound = '<false>'\n",
    "        \n",
    "        ### src words\n",
    "        for syl_id, s in enumerate(line_syllables):\n",
    "            print(s, end='  ')\n",
    "            ## is accented:\n",
    "            if \"'\" in str(s): ## strong\n",
    "                mtype = \"<strong>\"\n",
    "            elif \"`\" in str(s):\n",
    "                mtype = \"<substrong>\"\n",
    "            else:\n",
    "                mtype = \"<weak>\"\n",
    "            length = \"<long>\" if \"ː\" in str(s) else \"<short>\"\n",
    "            # data_sample['src_strength'].append(mtype)\n",
    "            # data_sample['src_length'].append(length)\n",
    "            if syl_id == len(line_syllables)-1:\n",
    "                data_sample['src_phrase'].append('<true>')\n",
    "            else:\n",
    "                data_sample['src_phrase'].append('<false>')\n",
    "\n",
    "    # data_sample['src_strength'] = data_sample['src_strength'] * 5\n",
    "    # data_sample['src_length'] = data_sample['src_length'] * 6\n",
    "    data_sample['src_phrase'] = data_sample['src_phrase'] * rep\n",
    "    return data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be3bfaa8-d010-4ad7-b880-b24def90520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'heɪ  'ʤuːd  'doʊnt  'meɪk  'ɪt  'bæd  'teɪk  eɪ  'sæd  'sɔːŋ  ænd  'meɪk  'ɪt  'bɛ  tɛː  rɪ  'mɛm  bɛː  tuː  'lɛt  hɛː  ɪn  'tuː  jɔːr  'hɑrt  'ðɛn  juː  kæn  'stɑrt  tuː  'meɪk  'ɪt  'bɛ  tɛː  'heɪ  'ʤuːd  'doʊnt  'biː  ə  'freɪd  juː  wɛː  'meɪd  tuː  'goʊ  aʊt  ænd  'gɛt  hɛː  ðə  'mɪ  nət  juː  'lɛt  hɛː  'ən  dɛː  jɔːr  'skɪn  'ðɛn  juː  bɪ  'gɪn  tuː  'meɪk  'ɪt  'bɛ  tɛː  ænd  'ɛ  niː  `taɪm  juː  'fiːl  ðə  'peɪn  'heɪ  'ʤuːd  rɪ  'freɪn  'doʊnt  'kæ  riː  ðə  'wɛːld  ə  'pɑn  jɔːr  'ʃoʊl  dɛːz  fɔːr  'wɛl  juː  'noʊ  'ðæt  ɪts  eɪ  'fuːl  'huː  'pleɪz  'ɪt  'kuːl  baɪ  'meɪ  kɪŋ  hɪz  'wɛːld  eɪ  'lɪ  təl  'koʊl  dɛː  "
     ]
    }
   ],
   "source": [
    "lyrics = '''Hey Jude don't make it bad\n",
    "Take a sad song and make it better\n",
    "Remember to let her into your heart\n",
    "Then you can start to make it better\n",
    "Hey Jude don't be afraid\n",
    "You were made to go out and get her\n",
    "The minute you let her under your skin\n",
    "Then you begin to make it better\n",
    "And anytime you feel the pain\n",
    "hey Jude refrain\n",
    "Don't carry the world upon your shoulders\n",
    "For well you know that it's a fool who plays it cool\n",
    "By making his world a little colder\n",
    "'''\n",
    "sample = convert_lyrics_to_input(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3922b0de-b535-4295-a0e0-0960af9b9495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɪn  ðə  'naɪt  ðə  'stɑrz  'duː  'ʃaɪn  'wɪ  spɛːz  'sɑft  ðə  'briːz  'ɪz  'kaɪnd  'driːmz  ən  'foʊld  ɪn  'sɪl  vɛː  'laɪt  'muːn  `lɪt  'pæðz  eɪ  'saɪ  lənt  'gaɪd  "
     ]
    }
   ],
   "source": [
    "lyrics = '''In the night, the stars do shine,\n",
    "Whispers soft, the breeze is kind.\n",
    "Dreams unfold, in silver light,\n",
    "Moonlit paths, a silent guide.\n",
    "'''\n",
    "sample = convert_lyrics_to_input(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df9084e6-17fc-416b-a2a3-ca9b839ef10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics.strip().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "86b780a0-a2b8-4ae8-b51d-d8d3bd5d391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_l2m(data_sample, output_dir='./'):\n",
    "    ## -------------------\n",
    "    ##     Bart Model\n",
    "    ## -------------------\n",
    "    set_seed()\n",
    "    print(f\"Using device: {device} for inferences custom samples\")\n",
    "    \n",
    "    # training conditions (for naming the ckpt)\n",
    "    lr = hparams['lr']\n",
    "    \n",
    "    ckpt_path = os.path.join(ckpt_dir, 'best.pt')\n",
    "\n",
    "    # load dictionary\n",
    "    event2word_dict, word2event_dict = pickle.load(open(f\"{binary_dir}/music_dict.pkl\", 'rb'))\n",
    "    \n",
    "\n",
    "    # load melody generation model based on skeleton framework\n",
    "    model = Bart(event2word_dict=event2word_dict, \n",
    "                 word2event_dict=word2event_dict, \n",
    "                 model_pth='',\n",
    "                 hidden_size=hparams['hidden_size'], \n",
    "                 num_layers=hparams['n_layers'], \n",
    "                 num_heads=hparams['n_head'], \n",
    "                 dropout=hparams['drop_prob'],).to(device)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=True)\n",
    "    model.eval()\n",
    "    print(f\"| Successfully loaded bart ckpt from {ckpt_path}.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    # Inference file path\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    # exp_date = get_time()\n",
    "    song_name = \"workshop\"\n",
    "    # melody_output_dir = os.path.join(hparams['output_dir'], f'{song_name}')\n",
    "    # melody_output_dir = f'./{song_name}'\n",
    "    melody_output_dir = os.path.join(output_dir, songname)\n",
    "    if not os.path.exists(melody_output_dir):\n",
    "        os.mkdir(melody_output_dir)\n",
    "\n",
    "\n",
    "    data = convert_to_data(data_sample, event2word_dict, word2event_dict)\n",
    "    print(data)\n",
    "    \n",
    "    try:\n",
    "        data_name = song_name\n",
    "\n",
    "        enc_inputs = {k: data[f'src_{k}'].to(device) for k in src_keys}\n",
    "        dec_inputs = {k: data[f'tgt_{k}'].to(device) for k in tgt_keys}\n",
    "        \n",
    "        print(enc_inputs['strength'].shape)\n",
    "\n",
    "        prompt_step = len(data_sample['tgt_bar'])\n",
    "\n",
    "        dec_inputs_selected = {\n",
    "            'bar': dec_inputs['bar'][:, :prompt_step],\n",
    "            'pos': dec_inputs['pos'][:, :prompt_step],\n",
    "            'token': dec_inputs['token'][:, :prompt_step],\n",
    "            'dur': dec_inputs['dur'][:, :prompt_step],\n",
    "            'phrase': dec_inputs['phrase'][:, :prompt_step],\n",
    "        }\n",
    "        print(enc_inputs)\n",
    "        print(dec_inputs_selected)\n",
    "\n",
    "        decode_length = enc_inputs['strength'].shape[-1]+2\n",
    "        max_sent_len = 1024\n",
    "\n",
    "        print(f\"Expected decode length: {decode_length}\")\n",
    "        _ = model.infer(enc_inputs=enc_inputs, \n",
    "                        dec_inputs_gt=dec_inputs_selected, \n",
    "                        decode_length=decode_length-prompt_step,\n",
    "                        sentence_maxlen=max_sent_len, \n",
    "                        temperature=hparams['temperature'], \n",
    "                        topk=hparams['topk'], \n",
    "                        device=device, \n",
    "                        output_dir=melody_output_dir, \n",
    "                        midi_name=data_name)\n",
    "\n",
    "        # print(f\"Generating {data_idx+1}/{len(test_loader)}, Name: {data_name}\")\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-\\nBad Item: {data_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cdca57e4-ea82-46a9-93b3-85c50395b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                                      | 7/1024 [00:00<00:14, 68.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5,\n",
      "         3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5,\n",
      "         3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3,\n",
      "         5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4,\n",
      "         4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4,\n",
      "         4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 140])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5,\n",
      "         3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5,\n",
      "         3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3,\n",
      "         5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4,\n",
      "         4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4,\n",
      "         4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 142\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▋                                                                                       | 139/1024 [00:01<00:12, 71.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 139\n",
      "./Hey Jude/Hey Jude.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer_l2m(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c059b92-56bf-48be-b29d-fbb300da6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate (lyrics_in):\n",
    "    test_sample = convert_lyrics_to_input(lyrics_in)\n",
    "    infer_l2m(sample, output_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fffd2-0143-41cd-b060-5d3fc83ef9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xailyr)",
   "language": "python",
   "name": "xailyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
