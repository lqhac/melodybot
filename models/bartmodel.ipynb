{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d7adbf-f244-45ce-94e6-25bea246baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import miditoolkit\n",
    "from miditoolkit.midi.containers import Marker, Instrument, TempoChange, Note\n",
    "from torch.nn import Parameter\n",
    "import math\n",
    "import torch.onnx.operators\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from utils.infer_utils import temperature_sampling\n",
    "from template_embedding import TemplateEmbedding\n",
    "from melody_embedding import MelodyEmbedding\n",
    "import numpy as np\n",
    "from transformers import BartForConditionalGeneration\n",
    "# from hugtransformers.src.transformers.models.bart.modeling_bart import BartModel, BartForConditionalGeneration\n",
    "# from hugtransformers.src.transformers.models.bart.tokenization_bart import BartTokenizer\n",
    "# from hugtransformers.src.transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from positional_encodings.torch_encodings import PositionalEncoding1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f4d847-cf87-4aab-9fa5-39368a8a3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bart(BartForConditionalGeneration):\n",
    "    def __init__(self, event2word_dict, word2event_dict, model_pth, hidden_size, num_layers, num_heads, dropout):\n",
    "        super().__init__(config, **kwargs)\n",
    "        # super(Bart, self).__init__()\n",
    "        self.event2word_dict = event2word_dict\n",
    "        self.word2event_dict = word2event_dict\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.pos_enc = PositionalEncoding1D(self.hidden_size)\n",
    "        \n",
    "        # self.model = BartForConditionalGeneration.from_pretrained(model_pth, ignore_mismatched_sizes=True)\n",
    "\n",
    "        ## embedding layers\n",
    "        self.src_emb = TemplateEmbedding(event2word_dict=event2word_dict,  d_embed=hidden_size, drop_prob=self.dropout)\n",
    "        self.tgt_emb = MelodyEmbedding(event2word_dict=event2word_dict, d_embed=hidden_size, drop_prob=self.dropout)\n",
    "        \n",
    "        self.lm = nn.Linear(self.hidden_size, self.tgt_emb.total_size)\n",
    "        \n",
    "\n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        cond_embeds = self.src_embed(**enc_inputs)\n",
    "        tgt_embeds = self.tgt_emb(dec_inputs['word'])\n",
    "        \n",
    "        outputs = super().forward(inputs_embeds=cond_embeds,\n",
    "                                 decoder_inputs_embeds=tgt_embeds,\n",
    "                                 labels=dec_inputs['token'])\n",
    "        \n",
    "        # Extract the hidden states from the decoder layers\n",
    "        dec_hidden_states = outputs.decoder_hidden_states\n",
    "        dec_outputs = self.lm(dec_hidden_states)\n",
    "        model_outputs = split_dec_outputs(dec_outputs)\n",
    "        \n",
    "        return dec_outputs\n",
    "    \n",
    "    def split_dec_outputs(self, dec_outputs):\n",
    "        bar_out_size = self.src_embed.bar_size\n",
    "        pos_out_size = bar_out_size + self.src_embed.pos_size\n",
    "        token_out_size = pos_out_size + self.src_embed.token_size\n",
    "        dur_out_size = token_out_size + self.src_embed.dur_size\n",
    "        phrase_out_size = dur_out_size + self.src_embed.phrase_size\n",
    "        \n",
    "        # word_out_size = self.lyr_embed.word_size\n",
    "        # rem_out_size = word_out_size + self.lyr_embed.rem_size\n",
    "        bar_out = dec_outputs[:, :, : bar_out_size]\n",
    "        pos_out = dec_outputs[:, :, bar_out_size: pos_out_size]\n",
    "        token_out = dec_outputs[:, :, pos_out_size: token_out_size]\n",
    "        dur_out = dec_outputs[:, :, token_out_size: dur_out_size]\n",
    "        phrase_out = dec_outputs[:, :, dur_out_size: phrase_out_size]\n",
    "        \n",
    "        return bar_out, pos_out, token_out, dur_out, phrase_out\n",
    "    \n",
    "    def infer (self, tgt_tknzr, enc_inputs, dec_inputs_gt, sentence_maxlen, temperature, topk, device, num_syllables):\n",
    "        sampling_func = partial(temperature_sampling, temperature=temperature, topk=topk)\n",
    "\n",
    "        bsz, _ = dec_inputs_gt['word'].shape\n",
    "        decode_length = sentence_maxlen  # the max number of Tokens in a midi\n",
    "\n",
    "        dec_inputs = dec_inputs_gt\n",
    "\n",
    "        tf_steps = dec_inputs_gt['word'].shape[1]  ## number of teacher-forcing steps\n",
    "        sentence_len = dec_inputs_gt['word'].shape[1]\n",
    "\n",
    "        is_end = False\n",
    "        xe = []\n",
    "        \n",
    "        num_syllables_remaining = num_syllables\n",
    "        sentence_num = 0\n",
    "        \n",
    "        for step in tqdm(range(decode_length)):\n",
    "            cond_embeds = self.mel_embed(**enc_inputs)\n",
    "            tgt_embeds = self.tgt_word_emb(dec_inputs['word'])\n",
    "            # gt_size = dec_inputs['word'].shape[-1]\n",
    "            # gt_labels = dec_inputs_full['word'][:, :gt_size]\n",
    "            \n",
    "            model_outputs = self.model(inputs_embeds=cond_embeds,\n",
    "                                       decoder_inputs_embeds=tgt_embeds)\n",
    "                                       # labels=gt_labels) \n",
    "            predicts = model_outputs.logits\n",
    "            \n",
    "            word_predict = predicts\n",
    "\n",
    "            word_logits = word_predict[:, -1, :].cpu().squeeze().detach().numpy()\n",
    "\n",
    "            word_id = sampling_func(logits=word_logits)\n",
    "            \n",
    "            # xe_loss = model_outputs.loss\n",
    "            # print(f\"loss: {model_outputs.loss}\")\n",
    "            # xe.append(xe_loss)\n",
    "            \n",
    "            \"\"\"\n",
    "            if word_id in tgt_tknzr.encode(\"<sep>\"):\n",
    "                sentence_num += 1\n",
    "                if sentence_num >= tgt_sent_num:\n",
    "                    break\n",
    "            \"\"\"\n",
    "            \n",
    "            if word_id in tgt_tknzr.encode(\"</s>\"):\n",
    "                is_end = True\n",
    "\n",
    "            if is_end:\n",
    "                token_out = list(dec_inputs['word'].cpu().squeeze().detach().numpy())\n",
    "                lyric_out = tgt_tknzr.decode(token_out)\n",
    "                break\n",
    "            \n",
    "            token_str = tgt_tknzr.decode(word_id)\n",
    "            word_str = token_str.strip()\n",
    "            word_txt = p.Text(word_str)\n",
    "            word_syll_num = len(word_txt.syllables())\n",
    "            \n",
    "            if token_str[0] == ' ':\n",
    "                num_syllables_remaining = num_syllables_remaining - word_syll_num\n",
    "            # num_syllables_token = self.event2word_dict['Remainder'][f\"Remain_{num_syllables_remaining}\"]\n",
    "            num_syllables_token = 0\n",
    "            \n",
    "            # print(f\"wordid: {word_id} word: {token_str}, syllable: {word_syll_num}, remain: {num_syllables_remaining}\")\n",
    "            \n",
    "            dec_inputs = {\n",
    "                'word': torch.cat((dec_inputs['word'], torch.LongTensor([[word_id]]).to(device)), dim=1),\n",
    "                'remainder': torch.cat((dec_inputs['remainder'], torch.LongTensor([[num_syllables_token]]).to(device)), dim=1),\n",
    "            }\n",
    "            \n",
    "            # xe_loss = xe_loss(word_predict[:, :-1], tgt_word) * hparams['lambda_word']\n",
    "            \n",
    "        if not is_end:\n",
    "            token_out = list(dec_inputs['word'].cpu().squeeze().detach().numpy())\n",
    "            lyric_out = f\"{tgt_tknzr.decode(token_out)}</s>\" \n",
    "            # xe.append(xe_loss)\n",
    "        \n",
    "        ppl = 0.0\n",
    "        # ppl = math.exp(torch.stack(xe).mean())\n",
    "        return lyric_out, ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df2cfa-1906-4805-8020-50e3c6d399ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xailyr)",
   "language": "python",
   "name": "xailyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
